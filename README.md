# PatchTST (ICLR 2023)

## 1 èƒŒæ™¯ä»‹ç»

> æ—¶é—´åºåˆ—é¢„æµ‹æ˜¯æ—¶é—´åºåˆ—åˆ†æä¸­æœ€é‡è¦çš„ä»»åŠ¡ä¹‹ä¸€ã€‚éšç€æ·±åº¦å­¦ä¹ æ¨¡å‹çš„å¿«é€Ÿå‘å±•ï¼Œè¿™ä¸€é¢†åŸŸçš„ç ”ç©¶å·¥ä½œæ˜¾è‘—å¢åŠ ã€‚æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸ä»…åœ¨é¢„æµ‹ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œè¿˜åœ¨è¡¨ç¤ºå­¦ä¹ ä¸­å±•ç°äº†å“è¶Šçš„æ€§èƒ½ï¼Œé€šè¿‡æå–æŠ½è±¡è¡¨ç¤ºï¼Œè¿™äº›æ¨¡å‹å¯ä»¥è¿ç§»åˆ°åˆ†ç±»å’Œå¼‚å¸¸æ£€æµ‹ç­‰ä¸‹æ¸¸ä»»åŠ¡ä¸­ï¼Œè¾¾åˆ°æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚
>
> åœ¨ä¼—å¤šæ·±åº¦å­¦ä¹ æ¨¡å‹ä¸­ï¼ŒTransformeråœ¨è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ã€è®¡ç®—æœºè§†è§‰ï¼ˆCVï¼‰ã€è¯­éŸ³å¤„ç†ç­‰åº”ç”¨é¢†åŸŸå–å¾—äº†å·¨å¤§æˆåŠŸã€‚æœ€è¿‘ï¼ŒTransformerä¹Ÿè¢«æˆåŠŸåº”ç”¨äºæ—¶é—´åºåˆ—æ•°æ®ï¼Œå…¶æ³¨æ„åŠ›æœºåˆ¶å¯ä»¥è‡ªåŠ¨å­¦ä¹ åºåˆ—å…ƒç´ ä¹‹é—´çš„è¿æ¥ï¼Œå› æ­¤éå¸¸é€‚åˆé¡ºåºå»ºæ¨¡ä»»åŠ¡ã€‚å°½ç®¡å…·æœ‰å¤æ‚è®¾è®¡çš„Transformeræ¨¡å‹åœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­å–å¾—äº†æ˜¾è‘—æˆæœï¼ˆå¦‚Informerã€Autoformerå’ŒFEDformerï¼‰ï¼Œä½†æœ€è¿‘çš„ç ”ç©¶è¡¨æ˜ï¼Œç®€å•çš„çº¿æ€§æ¨¡å‹åœ¨å¤šç§å¸¸è§åŸºå‡†æµ‹è¯•ä¸­å¯ä»¥è¶…è¶Šä¹‹å‰æ‰€æœ‰çš„Transformeræ¨¡å‹ï¼Œè¿™å¯¹Transformeråœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„æœ‰æ•ˆæ€§æå‡ºäº†è´¨ç–‘ã€‚



## 2 è®ºæ–‡æ¦‚è¿°

æœ¬æ–‡æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„`Transformer`æ¨¡å‹è®¾è®¡ï¼Œæ—¨åœ¨è§£å†³å¤šå˜é‡æ—¶é—´åºåˆ—é¢„æµ‹å’Œè‡ªç›‘ç£è¡¨ç¤ºå­¦ä¹ é—®é¢˜ã€‚è¯¥æ¨¡å‹ç”±ä¸¤ä¸ªå…³é”®ç»„ä»¶æ„æˆï¼š

(**i**) å°†æ—¶é—´åºåˆ—åˆ†å‰²æˆå­åºåˆ—çº§åˆ«çš„patchï¼Œå¹¶ä½œä¸ºè¾“å…¥tokenä¼ é€’ç»™Transformerï¼›

(**ii**) é€šé“ç‹¬ç«‹æ€§ï¼Œæ¯ä¸ªé€šé“åŒ…å«å•ä¸€çš„å•å˜é‡æ—¶é—´åºåˆ—ï¼Œå¹¶åœ¨æ‰€æœ‰åºåˆ—ä¸­å…±äº«ç›¸åŒçš„åµŒå…¥å’ŒTransformeræƒé‡ã€‚patchingè®¾è®¡è‡ªç„¶å…·æœ‰ä¸‰é‡å¥½å¤„ï¼šä¿ç•™åµŒå…¥ä¸­çš„å±€éƒ¨è¯­ä¹‰ä¿¡æ¯ï¼›åœ¨ç›¸åŒçš„å›æº¯çª—å£ä¸‹ï¼Œæ³¨æ„åŠ›å›¾çš„è®¡ç®—å’Œå†…å­˜ä½¿ç”¨é‡æˆå¹³æ–¹é™ä½ï¼›æ¨¡å‹å¯ä»¥å…³æ³¨æ›´é•¿çš„å†å²æ•°æ®ã€‚

æˆ‘ä»¬çš„é€šé“ç‹¬ç«‹patchæ—¶é—´åºåˆ—Transformerï¼ˆPatchTSTï¼‰ä¸ç°æœ‰çš„æœ€å…ˆè¿›çš„Transformeræ¨¡å‹ç›¸æ¯”ï¼Œæ˜¾è‘—æé«˜äº†é•¿æœŸé¢„æµ‹çš„å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å°†è¯¥æ¨¡å‹åº”ç”¨äºè‡ªç›‘ç£é¢„è®­ç»ƒä»»åŠ¡ï¼Œå¹¶åœ¨å¾®è°ƒæ€§èƒ½ä¸Šå–å¾—äº†ä¼˜å¼‚è¡¨ç°ï¼Œè¶…è¶Šäº†åœ¨å¤§å‹æ•°æ®é›†ä¸Šçš„ç›‘ç£è®­ç»ƒã€‚å°†ä¸€ä¸ªæ•°æ®é›†ä¸Šçš„æ©ç é¢„è®­ç»ƒè¡¨ç¤ºè¿ç§»åˆ°å…¶ä»–æ•°æ®é›†ä¸Šä¹Ÿäº§ç”Ÿäº†æœ€å…ˆè¿›çš„é¢„æµ‹å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡ï¼š**

ğŸŒŸ **è¡¥ä¸**ï¼šå°†æ—¶é—´åºåˆ—åˆ†å‰²æˆå­ç³»åˆ—çº§åˆ«çš„è¡¥ä¸ï¼Œè¿™äº›è¡¥ä¸ä½œä¸º `Transformer` çš„è¾“å…¥tokenã€‚

ğŸŒŸ **é€šé“ç‹¬ç«‹æ€§**ï¼šæ¯ä¸ªé€šé“éƒ½åŒ…å«ä¸€ä¸ªå•å˜é‡æ—¶é—´åºåˆ—ï¼Œè¯¥æ—¶é—´åºåˆ—åœ¨æ‰€æœ‰åºåˆ—ä¸­å…±äº«ç›¸åŒçš„åµŒå…¥å’Œ Transformer æƒé‡ã€‚

![model](https://raw.githubusercontent.com/Harris-H/PatchTST/main/pic/model.png)

## 

## 3 PyTorchè®­ç»ƒè„šæœ¬è¿ç§»è‡³MindSporeæ¡†æ¶

æœ¬é¡¹ç›®ä½¿ç”¨`MindTorch`å°†PyTorchè®­ç»ƒè„šæœ¬é«˜æ•ˆè¿ç§»è‡³MindSporeæ¡†æ¶æ‰§è¡Œã€‚

**MindTorchä»‹ç»ï¼š**

>ç›®çš„æ˜¯åœ¨ä¸æ”¹å˜åŸæœ‰PyTorchç”¨æˆ·çš„ä½¿ç”¨ä¹ æƒ¯æƒ…å†µä¸‹ï¼Œä½¿å¾—PyTorchä»£ç èƒ½åœ¨æ˜‡è…¾ä¸Šè·å¾—é«˜æ•ˆæ€§èƒ½ã€‚

![image-20240531150554354](https://raw.githubusercontent.com/Harris-H/PatchTST/main/pic/mindtorch.png)

- **PyTorchæ¥å£æ”¯æŒ**ï¼š MindTorchç›®å‰æ”¯æŒå¤§éƒ¨åˆ†PyTorchå¸¸ç”¨æ¥å£é€‚é…ã€‚ç”¨æˆ·æ¥å£ä½¿ç”¨æ–¹å¼ä¸å˜ï¼ŒåŸºäºMindSporeåŠ¨æ€å›¾æˆ–é™æ€å›¾æ¨¡å¼ä¸‹æ‰§è¡Œåœ¨æ˜‡è…¾ç®—åŠ›å¹³å°ä¸Šã€‚å¯ä»¥åœ¨[torchæ¥å£æ”¯æŒåˆ—è¡¨](SupportedList.md)ä¸­æŸ¥çœ‹æ¥å£æ”¯æŒæƒ…å†µã€‚
- **TorchVisionæ¥å£æ”¯æŒ**ï¼š MindTorch TorchVisionæ˜¯è¿ç§»è‡ªPyTorchå®˜æ–¹å®ç°çš„è®¡ç®—æœºè§†è§‰å·¥å…·åº“ï¼Œå»¶ç”¨PyTorchå®˜æ–¹APIè®¾è®¡ä¸ä½¿ç”¨ä¹ æƒ¯ï¼Œå†…éƒ¨è®¡ç®—è°ƒç”¨MindSporeç®—å­ï¼Œå®ç°ä¸torchvisionåŸå§‹åº“åŒç­‰åŠŸèƒ½ã€‚å¯ä»¥åœ¨[TorchVisionæ¥å£æ”¯æŒåˆ—è¡¨](TorchVision_SupportedList.md)ä¸­æŸ¥çœ‹æ¥å£æ”¯æŒæƒ…å†µã€‚

---

### 3.1 MindSporeå®‰è£…

### 3.2 MindTorchå®‰è£…

- é€šè¿‡pipå®‰è£…

```sh
# (MindSporeç‰ˆæœ¬ >= 2.2.1)
pip install mindtorch 
# (MindSporeç‰ˆæœ¬ == 2.0.0)
pip install msadapter
```

- é€šè¿‡æºç å®‰è£…

```sh
git clone https://git.openi.org.cn/OpenI/MSAdapter.git
cd MSAdapter
python setup.py install
```

å¦‚æœå‡ºç°æƒé™ä¸è¶³çš„æç¤ºï¼Œè¯·æŒ‰ç…§å¦‚ä¸‹æ–¹å¼å®‰è£…ï¼š

```sh
python setup.py install --user || exit 1
```

---

### 3.3 ä½¿ç”¨MindTorchè¿ç§»

> ä½¿ç”¨MindTorchè¿ç§»PyTorchç½‘ç»œå‰ï¼Œç¬¬ä¸€æ­¥æ˜¯æ›¿æ¢å¯¼å…¥æ¨¡å—è·¯å¾„ã€‚

**æ–¹æ³•ä¸€ï¼šä¸€è¡Œä»£ç è‡ªåŠ¨æ›¿æ¢**

åœ¨PyTorchæºä»£ç ä¸»å…¥å£è°ƒç”¨`torch`ç³»åˆ—ç›¸å…³çš„åŒ…å¯¼å…¥éƒ¨åˆ†ä¹‹å‰è°ƒç”¨`from mindtorch.tools import mstorch_enable` ï¼Œä»£ç æ‰§è¡Œæ—¶torchåŒåçš„å¯¼å…¥æ¨¡å—ä¼šè‡ªåŠ¨è¢«è½¬æ¢ä¸ºmindtorchç›¸åº”çš„æ¨¡å—ã€‚

å¦‚æœ¬é¡¹ç›®çš„ä¸»å…¥å£ç¨‹åºæ˜¯ï¼š`run_longExp.py`ï¼Œé‚£ä¹ˆåœ¨æ–‡ä»¶æœ€å¼€å¤´åŠ å…¥ä»¥ä¸‹ä»£ç ï¼š

```python
from mindtorch.tools import mstorch_enable   # éœ€è¦åœ¨ä¸»å…¥å£æ–‡ä»¶å¯¼å…¥torchç›¸å…³æ¨¡å—çš„å‰é¢ä½¿ç”¨
```

**æ–¹æ³•äºŒï¼šå·¥å…·æ‰‹åŠ¨é¢„å…ˆæ›¿æ¢**

æ›¿æ¢ä»£ç ä¸­å¯¼å…¥`torch`ç›¸å…³åŒ…çš„ä»£ç ï¼Œå¯ä»¥åˆ©ç”¨mindtorch/toolsä¸‹æä¾›çš„replace_import_packageå·¥å…·å¯å¿«é€Ÿå®Œæˆå·¥ç¨‹ä»£ç ä¸­torchåŠtorchvisionç›¸å…³å¯¼å…¥åŒ…çš„æ›¿æ¢ã€‚

```sh
bash replace_import_package.sh [Project Path]
```

`Project Path`ä¸ºéœ€è¦è¿›è¡Œæ›¿æ¢çš„å·¥ç¨‹è·¯ç»ï¼Œé»˜è®¤ä¸ºï¼‚./ï¼‚ã€‚

æ–‡ä»¶ä½ç½®ï¼šhttps://openi.pcl.ac.cn/OpenI/MSAdapter/src/branch/master/mindtorch/tools/replace_import_package.sh

ç›´æ¥åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹è¿›è¡Œæ‰§è¡Œè¯¥å‘½ä»¤ï¼Œå³å¯è‡ªåŠ¨æ›¿æ¢æ‰€æœ‰ä»£ç ã€‚

ä¹Ÿå¯ä»¥é€æ–‡ä»¶æ‰‹åŠ¨çš„æ›¿æ¢æ–‡ä»¶ä¸­çš„å¯¼å…¥åŒ…éƒ¨åˆ†ä»£ç ï¼Œç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼š

```python
# æ›¿æ¢å‰
# import torch
# import torch.nn as nn
# import torch.nn.functional as F
# from torchvision import datasets, transforms

# æ›¿æ¢å
import mindtorch.torch as torch
import mindtorch.torch.nn as nn
import mindtorch.torch.nn.functional as F
from mindtorch.torchvision import datasets, transforms
```



---

**ç›‘ç£å­¦ä¹ å’Œè‡ªæˆ‘ç›‘ç£å­¦ä¹ çš„ä»£ç åˆ†ä¸º 2 ä¸ªæ–‡ä»¶å¤¹ï¼š** `PatchTST_supervised` å’Œ `PatchTST_self_supervised`

### 3.4 ç›‘ç£å­¦ä¹ 

- **å®‰è£…ä¾èµ–åŒ…ï¼š**

```sh
pip install -r requirements.txt
```

- **ä¸‹è½½æ•°æ®é›†:**

å¯ä»¥ä»[Autoformer](https://drive.google.com/drive/folders/1ZOYpTUa82_jCcxIdTmyr0LXQfvaM9vIy)ä¸‹è½½æ‰€æœ‰ç”¨åˆ°çš„æ•°æ®é›†ã€‚åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹åˆ›å»ºæ–‡ä»¶å¤¹ï¼š`./dataset`,å¹¶å°†æ‰€æœ‰ csv æ–‡ä»¶æ”¾åœ¨è¯¥ç›®å½•ä¸­ã€‚

![image-20240531152103148](https://raw.githubusercontent.com/Harris-H/PatchTST/main/pic/dataset.png)

å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œä¸‹è½½å®Œæˆåå¾—åˆ°çš„æ•°æ®é›†ã€‚

- **è®­ç»ƒï¼š**

æ‰€æœ‰è„šæœ¬éƒ½åœ¨ç›®å½•ä¸­ `./scripts/PatchTST` ã€‚é»˜è®¤å‹å·ä¸º PatchTST/42ã€‚ä¾‹å¦‚ï¼Œå¦‚æœè¦è·å–å¤©æ°”æ•°æ®é›†çš„å¤šå˜é‡é¢„æŠ¥ç»“æœï¼Œåªéœ€è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œå³å¯åœ¨è®­ç»ƒå®Œæˆåæ‰“å¼€ `./result.txt` æŸ¥çœ‹ç»“æœï¼š

```sh
sh ./scripts/PatchTST/weather.sh
```

### 3.5 è‡ªç›‘ç£å­¦ä¹ 

- ä¸2.4å‰ä¸¤ä¸ªæ­¥éª¤ä¸€æ ·ï¼Œ**å®‰è£…ä¾èµ–åŒ…**å¹¶**ä¸‹è½½æ•°æ®é›†**ã€‚

- é¢„è®­ç»ƒï¼šscirpt patchtst_pretrain.pyæ˜¯è®­ç»ƒ PatchTST/64ã€‚è¦åœ¨ ettm1 ä¸Šä½¿ç”¨å•ä¸ª GPU è¿è¡Œä»£ç ï¼Œåªéœ€è¿è¡Œä»¥ä¸‹å‘½ä»¤ã€‚

```sh
python patchtst_pretrain.py --dset ettm1 --mask_ratio 0.4
```

æ¨¡å‹å°†ä¿å­˜åˆ°ä¸‹æ¸¸ä»»åŠ¡çš„ `saved_model` æ–‡ä»¶å¤¹ä¸­ã€‚åœ¨`patchtst_pretrain.py`è„šæœ¬ä¸­è¿˜å¯ä»¥è®¾ç½®å…¶ä»–å‡ ä¸ªå‚æ•°ã€‚

- å¾®è°ƒï¼šè„šæœ¬patchtst_finetune.pyç”¨äºå¾®è°ƒæ­¥éª¤ã€‚å¯ä»¥å¯¹æ•´ä¸ªç½‘ç»œè¿›è¡Œlinear_probingæˆ–å¾®è°ƒã€‚

```sh
python patchtst_finetune.py --dset ettm1 --pretrained_model <model_name>
```

## 4 å®éªŒç»“æœ

### 4.1 ç›‘ç£å­¦ä¹ 

ä¸åŸºäº Transformer çš„å‹å·æ‰€èƒ½æä¾›çš„æœ€ä½³ç»“æœç›¸æ¯”ï¼ŒPatchTST/64 å®ç°äº† MSE æ€»ä½“å‡å°‘ **21.0%** å’Œ MAE å‡å°‘ **16.7%**ï¼Œè€Œ PatchTST/42 å®ç°äº† MSE æ€»ä½“å‡å°‘ **20.2%** å’Œ MAE å‡å°‘ **16.4%**ã€‚å®ƒçš„æ€§èƒ½ä¹Ÿä¼˜äºå…¶ä»–éåŸºäº Transformer çš„æ¨¡å‹ï¼Œå¦‚ DLinearã€‚

![table3](https://raw.githubusercontent.com/Harris-H/PatchTST/main/pic/table3.png)

### 4.2 è‡ªæˆ‘ç›‘ç£å­¦ä¹ 

ä¸å…¶ä»–ç›‘ç£å’Œè‡ªç›‘ç£æ¨¡å‹è¿›è¡Œäº†æ¯”è¾ƒï¼Œè‡ªç›‘ç£ PatchTST èƒ½å¤Ÿä¼˜äºæ‰€æœ‰åŸºçº¿ã€‚

![table4](https://raw.githubusercontent.com/Harris-H/PatchTST/main/pic/table4.png)

![table6](https://raw.githubusercontent.com/Harris-H/PatchTST/main/pic/table6.png)

æˆ‘ä»¬è¿˜æµ‹è¯•äº†å°†é¢„è®­ç»ƒæ¨¡å‹è½¬ç§»åˆ°ä¸‹æ¸¸ä»»åŠ¡çš„èƒ½åŠ›ã€‚

![table5](https://raw.githubusercontent.com/Harris-H/PatchTST/main/pic/table5.png)

### 4.3 é•¿å›æº¯çª—å£çš„æ•ˆç‡

éšç€å›æº¯çª—å£çš„å¢åŠ ï¼ŒPatchTST ä¼šæŒç»­é™ä½ MSE åˆ†æ•°ï¼Œè¿™è¯å®äº†æ¨¡å‹èƒ½å¤Ÿä»æ›´é•¿çš„æ„Ÿå—é‡ä¸­å­¦ä¹ ã€‚

![varying_L](https://raw.githubusercontent.com/Harris-H/PatchTST/main/pic/varying_L.png)

## 5 è®­ç»ƒç»“æœ

### 5.1 è‡ªç›‘ç£å­¦ä¹ 

é¢„è®­ç»ƒå‚æ•°å¦‚ä¸‹æ‰€ç¤ºï¼Œå…¶ä»–é»˜è®¤ã€‚

| å‚æ•°åç§°       | å€¼    |
| -------------- | ----- |
| dset_pretrain  | ettm1 |
| context_points | 512   |
| target_points  | 96    |
| batch_size     | 64    |
| patch_len      | 12    |
| stride         | 12    |
| n_layers       | 3     |
| n_heads        | 16    |
| d_model        | 128   |
| mask_ratio     | 0.4   |

è®­ç»ƒæ—¥å¿—ï¼š

```sh
args: Namespace(batch_size=64, context_points=512, d_ff=512, d_model=128, dropout=0.2, dset_pretrain='ettm1', features='M', head_dropout=0.2, lr=0.0001, mask_ratio=0.4, model_type='based_model', n_epochs_pretrain=10, n_heads=16, n_layers=3, num_workers=0, patch_len=12, pretrained_model_id=1, revin=1, scaler='standard', stride=12, target_points=96)
number of patches: 42
number of model params 603404
suggested_lr 0.000298364724028334
number of patches: 42
number of model params 603404
          epoch     train_loss     valid_loss           time
Better model found at epoch 0 with valid_loss value: 0.9633879239606127.
              0       0.987340       0.963388          00:23
              1       0.969473       0.964801          00:23
Better model found at epoch 2 with valid_loss value: 0.7999917088347921.
              2       0.942842       0.799992          00:23
Better model found at epoch 3 with valid_loss value: 0.4354643907275711.
              3       0.682230       0.435464          00:23
Better model found at epoch 4 with valid_loss value: 0.3089567876435996.
              4       0.509751       0.308957          00:23
Better model found at epoch 5 with valid_loss value: 0.2819502188183807.
              5       0.403407       0.281950          00:23
Better model found at epoch 6 with valid_loss value: 0.2734085450287199.
              6       0.368505       0.273409          00:23
Better model found at epoch 7 with valid_loss value: 0.26829308841630195.
              7       0.354000       0.268293          00:23
Better model found at epoch 8 with valid_loss value: 0.2661328766069475.
              8       0.347698       0.266133          00:23
Better model found at epoch 9 with valid_loss value: 0.26483733930525166.
              9       0.344991       0.264837          00:23
pretraining completed

```



### 5.2 ç›‘ç£å­¦ä¹ 

è¿™é‡Œä»¥ç›‘ç£å­¦ä¹ ä¸ºä¾‹ï¼Œåˆ©ç”¨`PatchTST/42`è·å–å¤©æ°”æ•°æ®é›†çš„å¤šå˜é‡é¢„æŠ¥ç»“æœã€‚

```sh
sh ./scripts/PatchTST/weather.sh
```

#### a) é¢„æµ‹é•¿åº¦ä¸º96æ—¶

å½“é¢„æµ‹é•¿åº¦`pre_len`å‚æ•°ä¸º96æ—¶ï¼Œè®­ç»ƒæ—¥å¿—å¦‚ä¸‹ï¼š

```sh
Args in experiment:
Namespace(activation='gelu', affine=0, batch_size=128, c_out=7, checkpoints='./checkpoints/', d_ff=256, d_layers=1, d_model=128, data='custom', data_path='weather.csv', dec_in=7, decomposition=0, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.2, e_layers=3, embed='timeF', embed_type=0, enc_in=21, factor=1, fc_dropout=0.2, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=48, learning_rate=0.0001, loss='mse', lradj='type3', model='PatchTST', model_id='336_96', moving_avg=25, n_heads=16, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=20, pct_start=0.3, pred_len=96, random_seed=2021, revin=1, root_path='./dataset/', seq_len=336, stride=8, subtract_last=0, target='OT', test_flop=False, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : 336_96_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 36456
val 5175
test 10444
	iters: 100, epoch: 1 | loss: 0.7078106
	speed: 0.2415s/iter; left time: 6835.8982s
	iters: 200, epoch: 1 | loss: 0.7264591
	speed: 0.2388s/iter; left time: 6733.1824s
Epoch: 1 cost time: 68.15874147415161
Epoch: 1, Steps: 284 | Train Loss: 0.7472540 Vali Loss: 0.5415610 Test Loss: 0.2214899
Validation loss decreased (inf --> 0.541561).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3509977
	speed: 0.5582s/iter; left time: 15640.3718s
	iters: 200, epoch: 2 | loss: 0.4071708
	speed: 0.2387s/iter; left time: 6662.4881s
Epoch: 2 cost time: 68.16583466529846
Epoch: 2, Steps: 284 | Train Loss: 0.4904773 Vali Loss: 0.4162776 Test Loss: 0.1690703
Validation loss decreased (0.541561 --> 0.416278).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 3 | loss: 0.4483804
	speed: 0.5584s/iter; left time: 15487.3502s
	iters: 200, epoch: 3 | loss: 0.4230699
	speed: 0.2389s/iter; left time: 6602.8151s
...................................................
...................................................
Epoch: 36 cost time: 68.18052196502686
Epoch: 36, Steps: 284 | Train Loss: 0.4094809 Vali Loss: 0.3949354 Test Loss: 0.1505278
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.090315438263264e-06
	iters: 100, epoch: 37 | loss: 0.5415239
	speed: 0.5584s/iter; left time: 10093.6534s
	iters: 200, epoch: 37 | loss: 0.9917629
	speed: 0.2388s/iter; left time: 4292.9295s
Epoch: 37 cost time: 68.18944597244263
Epoch: 37, Steps: 284 | Train Loss: 0.4093141 Vali Loss: 0.3935625 Test Loss: 0.1507389
EarlyStopping counter: 19 out of 20
Updating learning rate to 2.7812838944369375e-06
	iters: 100, epoch: 38 | loss: 0.5711303
	speed: 0.5603s/iter; left time: 9968.9802s
	iters: 200, epoch: 38 | loss: 0.5285525
	speed: 0.2388s/iter; left time: 4225.5097s
Epoch: 38 cost time: 68.19268894195557
Epoch: 38, Steps: 284 | Train Loss: 0.4089722 Vali Loss: 0.3933101 Test Loss: 0.1504345
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : 336_96_PatchTST_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
mse:0.15200510621070862, mae:0.20024904608726501, rse:0.513616681098938
```



æ¨¡å‹æµ‹è¯•ç»“æœä¸‹ï¼Œåˆ†åˆ«æ˜¯0è½®ã€20è½®ã€40è½®ã€60è½®ã€80è½®çš„ç»“æœï¼š

![test_result](https://raw.githubusercontent.com/Harris-H/PatchTST/main/pic/96_test_result.png)

---

#### b) é¢„æµ‹é•¿åº¦ä¸º192æ—¶

å½“ä¿®æ”¹é¢„æµ‹é•¿åº¦ä¸ºï¼šå½“é¢„æµ‹é•¿åº¦`pre_len`å‚æ•°ä¸º192æ—¶ï¼Œè®­ç»ƒæ—¥å¿—å¦‚ä¸‹ï¼š

```sh
Args in experiment:
Namespace(activation='gelu', affine=0, batch_size=128, c_out=7, checkpoints='./checkpoints/', d_ff=256, d_layers=1, d_model=128, data='custom', data_path='weather.csv', dec_in=7, decomposition=0, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.2, e_layers=3, embed='timeF', embed_type=0, enc_in=21, factor=1, fc_dropout=0.2, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=48, learning_rate=0.0001, loss='mse', lradj='type3', model='PatchTST', model_id='336_192', moving_avg=25, n_heads=16, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=20, pct_start=0.3, pred_len=192, random_seed=2021, revin=1, root_path='./dataset/', seq_len=336, stride=8, subtract_last=0, target='OT', test_flop=False, train_epochs=100, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : 336_192_PatchTST_custom_ftM_sl336_ll48_pl192_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 36360
val 5079
test 10348
	iters: 100, epoch: 1 | loss: 0.7699601
	speed: 0.2443s/iter; left time: 6914.9405s
	iters: 200, epoch: 1 | loss: 0.7081208
	speed: 0.2400s/iter; left time: 6769.4607s
Epoch: 1 cost time: 68.70572686195374
Epoch: 1, Steps: 284 | Train Loss: 0.7789939 Vali Loss: 0.5972105 Test Loss: 0.2579384
...................................................
...................................................
Epoch: 52, Steps: 284 | Train Loss: 0.4628612 Vali Loss: 0.4596826 Test Loss: 0.1950321
EarlyStopping counter: 14 out of 20
Updating learning rate to 5.726416897022355e-07
	iters: 100, epoch: 53 | loss: 0.5660292
	speed: 0.5665s/iter; left time: 7666.5226s
	iters: 200, epoch: 53 | loss: 0.4055823
	speed: 0.2401s/iter; left time: 3225.5280s
Epoch: 53 cost time: 68.69006490707397
Epoch: 53, Steps: 284 | Train Loss: 0.4628603 Vali Loss: 0.4589893 Test Loss: 0.1950957
EarlyStopping counter: 15 out of 20
Updating learning rate to 5.15377520732012e-07
	iters: 100, epoch: 54 | loss: 0.4464000
	speed: 0.5651s/iter; left time: 7487.2338s
	iters: 200, epoch: 54 | loss: 0.4713202
	speed: 0.2404s/iter; left time: 3160.9685s
Epoch: 54 cost time: 68.69320154190063
Epoch: 54, Steps: 284 | Train Loss: 0.4628062 Vali Loss: 0.4595098 Test Loss: 0.1950420
EarlyStopping counter: 16 out of 20
Updating learning rate to 4.6383976865881085e-07
	iters: 100, epoch: 55 | loss: 0.5797229
	speed: 0.5644s/iter; left time: 7316.9253s
	iters: 200, epoch: 55 | loss: 0.4732520
	speed: 0.2400s/iter; left time: 3087.9587s
Epoch: 55 cost time: 68.70202779769897
Epoch: 55, Steps: 284 | Train Loss: 0.4627469 Vali Loss: 0.4590654 Test Loss: 0.1950581
EarlyStopping counter: 17 out of 20
Updating learning rate to 4.174557917929298e-07
	iters: 100, epoch: 56 | loss: 0.4195119
	speed: 0.5662s/iter; left time: 7179.4083s
	iters: 200, epoch: 56 | loss: 0.4406218
	speed: 0.2401s/iter; left time: 3020.8005s
Epoch: 56 cost time: 68.69338417053223
Epoch: 56, Steps: 284 | Train Loss: 0.4628384 Vali Loss: 0.4601701 Test Loss: 0.1950181
EarlyStopping counter: 18 out of 20
Updating learning rate to 3.7571021261363677e-07
	iters: 100, epoch: 57 | loss: 0.3315992
	speed: 0.5642s/iter; left time: 6993.8902s
	iters: 200, epoch: 57 | loss: 0.4004918
	speed: 0.2402s/iter; left time: 2953.3031s
Epoch: 57 cost time: 68.68426299095154
Epoch: 57, Steps: 284 | Train Loss: 0.4627628 Vali Loss: 0.4581457 Test Loss: 0.1950388
EarlyStopping counter: 19 out of 20
Updating learning rate to 3.381391913522731e-07
	iters: 100, epoch: 58 | loss: 0.3953090
	speed: 0.5663s/iter; left time: 6859.4706s
	iters: 200, epoch: 58 | loss: 0.4274355
	speed: 0.2401s/iter; left time: 2884.2582s
Epoch: 58 cost time: 68.70291900634766
Epoch: 58, Steps: 284 | Train Loss: 0.4623488 Vali Loss: 0.4600674 Test Loss: 0.1950225
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : 336_192_PatchTST_custom_ftM_sl336_ll48_pl192_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10348
mse:0.1951362043619156, mae:0.2412061244249344, rse:0.5811452269554138
```

æ¨¡å‹æµ‹è¯•ç»“æœä¸‹ï¼Œåˆ†åˆ«æ˜¯0è½®ã€20è½®ã€40è½®ã€60è½®çš„ç»“æœï¼š

![image-20240531160648084](https://raw.githubusercontent.com/Harris-H/PatchTST/main/pic/192_test_result.png)





